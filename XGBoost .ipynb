{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = 'training_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 20 classes of training data\n",
      "unique labels:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "number of features:  20\n",
      "number of samples:  100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# instantiate empty arrays for features and labels\n",
    "Xtr = np.array([])\n",
    "ytr = np.array([])\n",
    "k = 0 # initialize\n",
    "\n",
    "# load data from the relevant files\n",
    "while True:\n",
    "    try:\n",
    "        # load data file\n",
    "        class_k = np.loadtxt(training_folder + 'Class{:}.csv'.format(k))\n",
    "        # extract features and labels\n",
    "        class_k_features = class_k[:,:-1] # extract features\n",
    "        class_k_labels  = class_k[:,-1].astype(np.int) # labels; convert to int\n",
    "        # append the features and labels to the arrays\n",
    "        Xtr = np.vstack([Xtr,class_k_features]) if Xtr.size else class_k_features\n",
    "        ytr = np.hstack([ytr,class_k_labels]) if ytr.size else class_k_labels\n",
    "        # increment counter\n",
    "        k += 1\n",
    "    except:\n",
    "        print('loaded %i classes of training data' %k)\n",
    "        break\n",
    "\n",
    "# examine shape\n",
    "num_classes = k\n",
    "num_features = Xtr.shape[1]\n",
    "num_samples = Xtr.shape[0]\n",
    "\n",
    "print('unique labels: ', np.unique(ytr))\n",
    "print('number of features: ', num_features)\n",
    "print('number of samples: ', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and testing \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr, ytr, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting XGBoost to the training set \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(max_depth=4)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting the Test set results\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data = 0.9609\n",
      "Accuracy on test data = 0.8973\n"
     ]
    }
   ],
   "source": [
    "acc_train = np.mean(y_pred_train == y_train)\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print('Accuracy on train data = {0:.4f}'.format(acc_train))\n",
    "print('Accuracy on test data = {0:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003050343357459284"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89399135 0.89278258 0.89813572 0.89349642 0.8980597  0.89207344\n",
      " 0.89371548 0.90128435 0.89556253 0.89986549]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "accuracies.mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
